# -*- coding: utf-8 -*-
"""Pytorch fundamentals Part 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Goxu0rXvS3PMYgK084R2jOFNfY-Snjrg
"""

import torch

tensor = torch.arange(0,10)
tensor

tensor.dtype

tensor = tensor.type(torch.float64)
tensor, tensor.dtype

squeezed_tensor = tensor.squeeze(dim=0)
squeezed_tensor, squeezed_tensor.shape

unsqueezed_tensor = squeezed_tensor.unsqueeze(dim=0)
unsqueezed_tensor, unsqueezed_tensor.shape

x_original = torch.rand(size=(224, 224, 3))
x_original.shape

x_permuted = x_original.permute(2, 0, 1)
x_permuted.shape

x_original[0, 0, 0] = 0.0888
x_original[0, 0, 0], x_permuted[0, 0, 0]

x = torch.arange(1, 10).reshape(1, 3, 3)
x, x.shape

x[0]

x[0][0]

x[0][2][2]

x[:, 0]

x[:, :, 1]

x[0, 1, 1]

x[0, 0, :]

x[0, 2, 2]

x[:, :, 2]

import numpy as np
array = np.arange(1.0, 8.0)
tensor = torch.from_numpy(array)
array, tensor

array.dtype

tensor.dtype

array = array + 1
array, tensor

tensor = torch.ones(7)
numpy_tensor = tensor.numpy()
tensor, numpy_tensor

numpy_tensor.dtype

tensor = tensor + 1
tensor, numpy_tensor #don't share memory

torch.rand(3, 3)
random_tensor_A = torch.rand(3, 4)
random_tensor_B = torch.rand(3, 4)

print(random_tensor_A)
print(random_tensor_B)
print(random_tensor_A == random_tensor_B)

RANDOM_SEED = 42
torch.manual_seed(RANDOM_SEED)

random_tensor_C = torch.rand(3, 4)
random_tensor_D = torch.rand(3, 4)

print(random_tensor_C)
print(random_tensor_D)
print(random_tensor_C == random_tensor_D)

!nvidia-smi

torch.cuda.is_available()

device = "cuda" if torch.cuda.is_available else "cpu"
device

torch.cuda.device_count()

tensor = torch.tensor([1, 2, 3], device="cpu")
print(tensor, tensor.device)

tensor_on_gpu = tensor.to(device)
tensor_on_gpu

tensor_on_gpu.cpu().numpy()

tensor_on_gpu

